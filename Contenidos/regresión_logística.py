# -*- coding: utf-8 -*-
"""Regresión_Logística.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NDo-rDazRjE_zoqf_wt6U79sbrSK3OL_
"""

# Regresión Logística
# Fórmula: 1/1+e-(b0+b1x)

import numpy as np
import matplotlib.pyplot as plt
import math

# Creamos una función logística vectorial (ufuncs)
logistica = np.frompyfunc(lambda b0, b1, x: 1 / (1 + math.exp(-(b0 + b1 * x))), 3, 1)

# Graficamos la función logistica con diferentes pendientes
plt.figure(figsize=(8, 4))

plt.scatter(np.arange(-5, 5, 0.1), logistica(0, 1, np.arange(-5, 5, 0.1)), color='green')
plt.scatter(np.arange(-5, 5, 0.1), logistica(0, 2, np.arange(-5, 5, 0.1)), color='gold')
plt.scatter(np.arange(-5, 5, 0.1), logistica(0, 3, np.arange(-5, 5, 0.1)), color='red')

plt.title('Función Logística Estándar - Diferentes "Pendientes"', fontsize=14.0)
plt.ylabel("Probabilidad", fontsize=13.0)
plt.xlabel("Valores", fontsize=13.0)
plt.show()

# ==================================================================================================================

# Taquicardia: Probabilidad y Clase
# Persona Normal de 60 a 100 latidos por minuto.
# Persona con Taquicardia de hasta 220 latidos por minuto

persona_normal = [65, 70, 80, 80, 80, 90, 95, 100, 105, 110]

persona_taquicardia = [105, 110, 110, 120, 120, 130, 140, 180, 185, 190]

# Graficamos una función logística
plt.figure(figsize=(6, 4))

# y = b0 + b1x
# y = -46.68057196 + 0.42460226x

plt.scatter(np.arange(60, 200, 0.1), logistica(-46.68057196, 0.42460226, np.arange(60, 200, 0.1)))

# Graficamos la frecuencia cardíaca de las personas
plt.scatter(persona_normal, [0]*10, marker='o', c='green', s=250, label="Normal")
plt.scatter(persona_taquicardia, [1]*10, marker='o', c='red', s=250, label="Taquicardia")

# Graficamos las probabilidades para tres (3) individuos
individuos = [80, 110, 180]

probabilidades = logistica(-46.68057196, 0.42460226, individuos)

plt.scatter(individuos, probabilidades, marker='*', c='darkorange', s=500)

plt.text(individuos[0]+7, 0.05, '%0.2f' % probabilidades[0], size=12, color='black')
plt.text(individuos[1]+7, 0.48, '%0.2f' % probabilidades[1], size=12, color='black')
plt.text(individuos[2]+7, 0.90, '%0.2f' % probabilidades[2], size=12, color='black')

plt.text(0, 1, 'TAQUICARDIA', size=12, color='red')
plt.text(0, 0, 'NORMAL', size=12, color='red')
plt.ylabel('Probabilidad de Taquicardia', fontsize=13.0)
plt.xlabel('Frecuencia cardiaca (latidos por minuto)', fontsize=13.0)
plt.legend(bbox_to_anchor=(1, 0.2))
plt.show()

# ==================================================================================================================

# Máxima Verosimilitud
# Diferentes funciones logísticas con diferentes 'pendientes'
plt.figure(figsize=(6, 4))

for b1 in np.arange(0.35, 0.49, 0.025):
  plt.scatter(np.arange(60, 200, 0.1), logistica(-46.68057196, b1, np.arange(60, 200, 0.1)), label='b_1=%0.2f' % b1)


# Graficamos la frecuencia cardiaca de las personas
plt.scatter(persona_normal, [0]*10, marker='o', c='green', s=250, label='Normal')
plt.scatter(persona_taquicardia, [1]*10, marker='o', c='red', s=250, label='Taquicardia')

plt.title('Máxima Verosimilitud', fontsize=18.0)
plt.text(0, 1, 'TAQUICARDIA', size=12, color='red')
plt.text(0, 0, 'NORMAL', size=12, color='red')
plt.ylabel('Probabilidad de Taquicardia', fontsize=13.0)
plt.xlabel('Frecuencia cardiaca (latidos por minuto)', fontsize=13.0)
plt.legend(bbox_to_anchor=(1, 1))
plt.show()

# ==================================================================================================================

# Modelo de Regresión Logística
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split

frecuencias_cardiacas = [[65], [70], [80], [80], [80],
                         [90], [95], [100], [105], [110],
                         [105], [110], [110], [120], [120],
                         [130], [140], [180], [185], [190]]

clase = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]

# Creamos conjuntos de entrenamiento y de prueba del modelo
datos_entera, datos_prueba, clase_entera, clase_prueba =  train_test_split(frecuencias_cardiacas, clase, test_size=0.30)

# Creamos el modelo de Regresión Logística
modelo = LogisticRegression().fit(datos_entera, clase_entera)
np.set_printoptions(suppress=True)
print(modelo.predict(datos_prueba))
print(modelo.predict_proba(datos_prueba))
print(modelo.score(datos_prueba, clase_prueba))
print(modelo.intercept_, modelo.coef_)

